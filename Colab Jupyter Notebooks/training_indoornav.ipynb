{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QEcp_uTqyW_"
      },
      "source": [
        "# Training eines Machine Learning Models\n",
        "In diesem Jupyter Notebook werden drei Modelle trainiert, die die Position innerhalb der Fachhochschule Wedel anhand von Bildern klassifizieren\n",
        "\n",
        "Das Training wurde auf Google Colab durchgeführt, daher können Pfadanpassungen für die Ausführung notwendig sein."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IusR2AtmvA7E"
      },
      "source": [
        "Imports und Konstanten "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JHbdvfzps9Q"
      },
      "outputs": [],
      "source": [
        "# Imports needed\n",
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "img_height = 320\n",
        "img_width = 180\n",
        "num_epochs = 15 # 15\n",
        "\n",
        "batch_size = 15\n",
        "\n",
        "\n",
        "nClasses_1 = 108\n",
        "nClasses_2 = 143\n",
        "nClasses_3 = 104\n",
        "\n",
        "input_shape = (img_height, img_width, 1) #3 for rgb\n",
        "SRC_DIR_1 = \"/content/training1\"\n",
        "SRC_DIR_2 = \"/content/training2\"\n",
        "SRC_DIR_3 = \"/content/training3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALsURbqKvQU8"
      },
      "source": [
        "Hierdurch wird eine Verbindung zu Google Drive hergestellt, um die Trainingsdaten zu erreichen. \n",
        "Diese müssen für jede Sitzung hochgeladen werden. Der Datensatz wird aus Google Drive geladen und in das lokale Filesystem von Colab entpackt.\n",
        "\n",
        "Zudem werden die Ordner angelegt, in die die Modelle später gespeichert werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "HXbF3eFOvQeK",
        "outputId": "31255a41-09d1-4448-8e53-0ff3893c6d54"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3qIuJZscXN7",
        "outputId": "0aae3fb7-1f6a-464c-ea3b-06c32b5518ab"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/gdrive/MyDrive/Thesis_ColabNotebooks/models/m1\n",
        "!mkdir /content/gdrive/MyDrive/Thesis_ColabNotebooks/models/m2\n",
        "!mkdir /content/gdrive/MyDrive/Thesis_ColabNotebooks/models/m3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ew7R3SlNVKY"
      },
      "source": [
        "Die Trainingsdaten werden aus Google Drive heraus entpackt und in das Filesystem von Colab selbst geladen, um ein möglichst schnelles Training zu ermöglichen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsDtmCYAQjRR"
      },
      "outputs": [],
      "source": [
        "!unzip /content/gdrive/MyDrive/Thesis_ColabNotebooks/TrainData/ABC.zip -d /content/training1\n",
        "!unzip /content/gdrive/MyDrive/Thesis_ColabNotebooks/TrainData/D.zip -d /content/training2\n",
        "!unzip /content/gdrive/MyDrive/Thesis_ColabNotebooks/TrainData/EF.zip -d /content/training3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_D5sn6IXaQI"
      },
      "source": [
        "Im nächsten Abschnitt wird eine GPU auf Colab gesucht. Damit kann ein Model auf der GPU trainiert werden statt auf der CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbI7x4VOXFZU",
        "outputId": "8504c6ed-6e38-4b35-aadd-d72c84c63020"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yij2cZfUUxJ"
      },
      "source": [
        "Preprocess nimmt die Bilder und splittet sie in Trainins- und Testdaten. Dabei werden die Bilder jeweils gelabelt und zwar abhängig des Ordners, in dem sie sich befinden. Ein Bild in Ordner A0012 bekommt dementsprechend das Label A0012. Das Label steht für Gebäudeteil A, Stockwerk 0, an Position 01 im Gang und Blickrichtung 2. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JpGF0ytUKi4"
      },
      "outputs": [],
      "source": [
        "def preprocess(source_dir):\n",
        "    ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        source_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"categorical\",  #int categorical, binary\n",
        "        color_mode=\"grayscale\",\n",
        "        batch_size=batch_size,\n",
        "        image_size=(img_height, img_width),  # reshape if not in this size\n",
        "        shuffle=True,\n",
        "        seed=123,\n",
        "        validation_split=0.1,\n",
        "        subset=\"training\",\n",
        "    )\n",
        "\n",
        "    ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        source_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"categorical\",  # categorical, binary\n",
        "        color_mode=\"grayscale\",\n",
        "        batch_size=batch_size,\n",
        "        image_size=(img_height, img_width),  # reshape if not in this size\n",
        "        shuffle=True,\n",
        "        seed=123,\n",
        "        validation_split=0.1,\n",
        "        subset=\"validation\",\n",
        "    )\n",
        "\n",
        "    return (ds_train, ds_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hier wird die interne Struktur des Models definiert, indem nacheinander Convolutional Layer, Max Pooling Layer, Dropout Layer sowie Dense Layer eingefügt werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvgRDKq3VVaV"
      },
      "outputs": [],
      "source": [
        "def create_model(nClasses):\n",
        "    \n",
        "    model = Sequential()\n",
        "    # The first two layers with 32 filters of window size 3x3\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25)) #prevents overfitting\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mit dieser Funktion wird ein Model kompiliert, die interne Struktur ausgegeben, trainiert und anschließend im übergebenen Ordner folder_in_drive gespeichert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nlb6RZxVnE6"
      },
      "outputs": [],
      "source": [
        "def train_model(model, ds_train, ds_validation, folder_in_drive):\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.fit(ds_train, epochs=num_epochs, verbose=2)\n",
        "    model.save('/content/gdrive/MyDrive/Thesis_ColabNotebooks/models/' + folder_in_drive)\n",
        "    model.evaluate(ds_validation, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vorbereitung der 3 Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWstKnNiVpEY",
        "outputId": "a7f24c66-afe1-4fce-9ec5-8bf61cbc4009"
      },
      "outputs": [],
      "source": [
        "(ds_train_m1, ds_validation_m1) = preprocess(SRC_DIR_1)\n",
        "(ds_train_m2, ds_validation_m2) = preprocess(SRC_DIR_2)\n",
        "(ds_train_m3, ds_validation_m3) = preprocess(SRC_DIR_3)\n",
        "\n",
        "model1 = create_model(nClasses_1)\n",
        "model2 = create_model(nClasses_2)\n",
        "model3 = create_model(nClasses_3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training Model 1 (Gebäudeteil A, B und C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9QaE_pzKnkq",
        "outputId": "90ca8485-7f89-4e0a-95b9-8d2177308fdf"
      },
      "outputs": [],
      "source": [
        "train_model(model1, ds_train_m1, ds_validation_m1, 'm1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training Model 2 (Gebäudeteil D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4NQlV_o7YcC",
        "outputId": "1ca06570-95c3-4584-d525-3d045ceed153"
      },
      "outputs": [],
      "source": [
        "train_model(model2, ds_train_m2, ds_validation_m2, 'm2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training Model 3 (Gebäudeteil E und F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEhaC1qMZiAm",
        "outputId": "b0e7351f-b265-4864-ea54-a8330083d966"
      },
      "outputs": [],
      "source": [
        "train_model(model3, ds_train_m3, ds_validation_m3, 'm3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "training_indoornav.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('indoor_nav')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "43d9d9cffffb19c0330bb8a6ae7a447754a934055925c615d6e5cbc08baefb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
